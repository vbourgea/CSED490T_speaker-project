{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.load('wav16.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(dataset['fold1'].item().get('sounds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = np.load('data_dl/ESC-50-master/audio_resampled/wav_complete.npz')\n",
    "split=3\n",
    "# Split to train and val\n",
    "train_sounds = []\n",
    "train_labels = []\n",
    "val_sounds = []\n",
    "val_labels = []\n",
    "for i in range(1, 6):\n",
    "    sounds = dataset['fold{}'.format(i)].item()['sounds']\n",
    "    labels = dataset['fold{}'.format(i)].item()['labels']\n",
    "    if i == split:\n",
    "        val_sounds.extend(sounds)\n",
    "        val_labels.extend(labels)\n",
    "    else:\n",
    "        train_sounds.extend(sounds)\n",
    "        train_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name={'crying_baby':0, 'glass_breaking':1, 'coughing':2}\n",
    "#train_labels=list(map(name.get, train_labels))\n",
    "#val_labels=list(map(name.get, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=one_hot_encode(train_labels)\n",
    "val_labels=one_hot_encode(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to have value between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound, factor=32768):\n",
    "    return [s/factor for s in sound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random crop of the sound values to have T-s window of sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(sound, size=24014):\n",
    "    cropped_sound=[]\n",
    "    for s in sound:\n",
    "        org_size = len(s)\n",
    "        start = random.randint(0, org_size - size)\n",
    "        cropped_s=s[start: start + size]\n",
    "        cropped_sound.append(cropped_s)\n",
    "    return cropped_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sound, pad=24014//2):\n",
    "    if len(sound)<80000:\n",
    "        padded_sound=[]\n",
    "        for i in range(len(sound)):\n",
    "            padded_s=np.pad(sound[i], pad, 'constant')\n",
    "            padded_sound.append(padded_s)\n",
    "    return padded_sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-crop for testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_crop(sounds,input_length=24014, n_crops=10):\n",
    "    multi_cropped_sounds=[]\n",
    "    for s in sounds:\n",
    "        stride = (len(s) - input_length) // (n_crops - 1)\n",
    "        multi_cropped_sound = [s[stride * i: stride * i + input_length] for i in range(n_crops)]\n",
    "        multi_cropped_sounds.append(np.array(multi_cropped_sound))\n",
    "    return multi_cropped_sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is supposed to be the pad parameter ?\n",
    "#train_sounds=padding(train_sounds, 24014//2) \n",
    "#val_sounds=padding(train_sounds, 24014//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of window = 1.5s (24014)\n",
    "\n",
    "Normalization constant = 32768 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=multi_crop(normalize(padding(val_sounds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.reshape(test_X, (-1, 24014, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 24014, 1, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y=np.repeat(val_labels, 10, axis=0)\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y=val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve : do the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes=3\n",
    "n_classes=50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the tensor is 4D : [batch, height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 24014,1, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 300 \n",
    "batch_size = 64\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "crop_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(epoch):\n",
    "    if (0<=epoch<=80):\n",
    "        return 0.01\n",
    "    if (80<epoch<=100):\n",
    "        return 0.001\n",
    "    if (100<epoch<= 120):\n",
    "        return 0.0001\n",
    "    else: return 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride =1\n",
    "\n",
    "No Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b,is_training, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.contrib.layers.batch_norm(x, is_training=is_training)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k_h=2, k_w=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k_h, k_w, 1], strides=[1, k_h, k_w, 1],padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of the parameters = He initialization\n",
    "\n",
    "Review the order (does the order actually matters ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[heigth_filter, width_filter, depth_filter, number of filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    #conv1\n",
    "    'wc1': tf.get_variable('W0', shape=(8,1,1,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv2\n",
    "    'wc2': tf.get_variable('W1', shape=(8,1,40,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv3\n",
    "    'wc3': tf.get_variable('W2', shape=(13,8,1,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv4\n",
    "    'wc4': tf.get_variable('W3', shape=(5,1,50,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc5': tf.get_variable('W4', shape=(50*11*14,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc6': tf.get_variable('W5', shape=(4096,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #output\n",
    "    'out': tf.get_variable('W6', shape=(4096,n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc2': tf.get_variable('B1', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc3': tf.get_variable('B2', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc4': tf.get_variable('B3', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc5': tf.get_variable('B4', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc6': tf.get_variable('B5', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'out': tf.get_variable('B6', shape=(n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_net(x, weights, biases):  \n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], is_training)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], is_training)\n",
    "    conv2 = maxpool2d(conv2, k_h=160, k_w=1)\n",
    "    \n",
    "    conv2=tf.reshape(conv2, [-1, 150, 40, 1])\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], is_training)\n",
    "    conv3 = maxpool2d(conv3, k_h=3, k_w=3)\n",
    "    \n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'], is_training)\n",
    "    conv4 = maxpool2d(conv4, k_h=3, k_w=1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc5 = tf.reshape(conv4, [-1, weights['wfc5'].get_shape().as_list()[0]])\n",
    "    fc5 = tf.add(tf.matmul(fc5, weights['wfc5']), biases['bfc5'])\n",
    "    fc5 = tf.nn.relu(fc5)\n",
    "    # Drop out\n",
    "    drop_out_fc5 = tf.nn.dropout(fc5, keep_prob)\n",
    "    \n",
    "    fc6 = tf.add(tf.matmul(drop_out_fc5, weights['wfc6']), biases['bfc6'])\n",
    "    fc6 = tf.nn.relu(fc6)\n",
    "    drop_out_fc6 = tf.nn.dropout(fc6, keep_prob)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(drop_out_fc6, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & optimizer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_momentum = 0.9\n",
    "momentum = tf.Variable(init_momentum, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = env_net(X, weights, biases)\n",
    "\n",
    "pred_train=logits\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred_train, labels=y))\n",
    "\n",
    "pred_test=tf.reduce_sum(tf.nn.softmax(logits),0)\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "#correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "correct_prediction_train = tf.equal(tf.argmax(pred_train, 1), tf.argmax(y, 1))\n",
    "correct_prediction_test = tf.equal(tf.argmax(pred_test, 0), tf.argmax(y, 1)[0])\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy_train = tf.reduce_mean(tf.cast(correct_prediction_train, tf.float32))\n",
    "accuracy_test=tf.cast(correct_prediction_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 4.192940, Training Accuracy= 0.01562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.01500\n",
      "Iter 1, Loss= 3.853369, Training Accuracy= 0.04688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.02250\n",
      "Iter 2, Loss= 3.852890, Training Accuracy= 0.04688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.02500\n",
      "Iter 3, Loss= 3.703879, Training Accuracy= 0.10938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.03250\n",
      "Iter 4, Loss= 3.705049, Training Accuracy= 0.07812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04000\n",
      "Iter 5, Loss= 3.601861, Training Accuracy= 0.12500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05750\n",
      "Iter 6, Loss= 3.487177, Training Accuracy= 0.07812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06500\n",
      "Iter 7, Loss= 3.314870, Training Accuracy= 0.12500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05500\n",
      "Iter 8, Loss= 3.278057, Training Accuracy= 0.17188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04500\n",
      "Iter 9, Loss= 3.277998, Training Accuracy= 0.07812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06000\n",
      "Iter 10, Loss= 3.065012, Training Accuracy= 0.18750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08250\n",
      "Iter 11, Loss= 3.129282, Training Accuracy= 0.14062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09000\n",
      "Iter 12, Loss= 2.858577, Training Accuracy= 0.21875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06250\n",
      "Iter 13, Loss= 2.658898, Training Accuracy= 0.23438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 14, Loss= 2.866426, Training Accuracy= 0.15625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09750\n",
      "Iter 15, Loss= 2.650857, Training Accuracy= 0.26562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09250\n",
      "Iter 16, Loss= 2.644201, Training Accuracy= 0.26562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08500\n",
      "Iter 17, Loss= 2.491693, Training Accuracy= 0.29688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 18, Loss= 2.586170, Training Accuracy= 0.28125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 19, Loss= 2.696522, Training Accuracy= 0.21875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09000\n",
      "Iter 20, Loss= 2.680602, Training Accuracy= 0.26562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07250\n",
      "Iter 21, Loss= 2.340200, Training Accuracy= 0.32812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06500\n",
      "Iter 22, Loss= 2.426487, Training Accuracy= 0.34375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06000\n",
      "Iter 23, Loss= 2.420993, Training Accuracy= 0.28125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06000\n",
      "Iter 24, Loss= 2.484632, Training Accuracy= 0.32812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05250\n",
      "Iter 25, Loss= 2.583972, Training Accuracy= 0.32812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05500\n",
      "Iter 26, Loss= 2.375853, Training Accuracy= 0.42188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08000\n",
      "Iter 27, Loss= 2.024407, Training Accuracy= 0.48438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 28, Loss= 2.303173, Training Accuracy= 0.32812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06500\n",
      "Iter 29, Loss= 2.132746, Training Accuracy= 0.29688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06500\n",
      "Iter 30, Loss= 2.203965, Training Accuracy= 0.37500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05250\n",
      "Iter 31, Loss= 2.226495, Training Accuracy= 0.37500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09000\n",
      "Iter 32, Loss= 2.066684, Training Accuracy= 0.48438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.04500\n",
      "Iter 33, Loss= 2.267897, Training Accuracy= 0.29688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05750\n",
      "Iter 34, Loss= 1.961178, Training Accuracy= 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06250\n",
      "Iter 35, Loss= 1.723518, Training Accuracy= 0.45312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06250\n",
      "Iter 36, Loss= 2.213590, Training Accuracy= 0.37500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 37, Loss= 1.975899, Training Accuracy= 0.42188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07750\n",
      "Iter 38, Loss= 2.117551, Training Accuracy= 0.40625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 39, Loss= 2.085478, Training Accuracy= 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09000\n",
      "Iter 40, Loss= 1.907552, Training Accuracy= 0.45312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08000\n",
      "Iter 41, Loss= 1.766488, Training Accuracy= 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08000\n",
      "Iter 42, Loss= 1.862964, Training Accuracy= 0.39062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08250\n",
      "Iter 43, Loss= 1.863316, Training Accuracy= 0.48438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08500\n",
      "Iter 44, Loss= 1.828450, Training Accuracy= 0.48438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 45, Loss= 1.940688, Training Accuracy= 0.43750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05500\n",
      "Iter 46, Loss= 1.904335, Training Accuracy= 0.42188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 47, Loss= 1.890419, Training Accuracy= 0.39062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07000\n",
      "Iter 48, Loss= 1.852407, Training Accuracy= 0.42188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06000\n",
      "Iter 49, Loss= 1.908845, Training Accuracy= 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09750\n",
      "Iter 50, Loss= 1.540827, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07250\n",
      "Iter 51, Loss= 1.584466, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07500\n",
      "Iter 52, Loss= 1.682715, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06000\n",
      "Iter 53, Loss= 1.555359, Training Accuracy= 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.11250\n",
      "Iter 54, Loss= 1.783277, Training Accuracy= 0.51562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09250\n",
      "Iter 55, Loss= 1.605020, Training Accuracy= 0.45312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10750\n",
      "Iter 56, Loss= 1.538434, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 57, Loss= 1.739310, Training Accuracy= 0.46875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07250\n",
      "Iter 58, Loss= 1.353598, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06250\n",
      "Iter 59, Loss= 1.703797, Training Accuracy= 0.51562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05500\n",
      "Iter 60, Loss= 1.489738, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07500\n",
      "Iter 61, Loss= 1.465592, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 62, Loss= 1.568254, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.06750\n",
      "Iter 63, Loss= 1.671339, Training Accuracy= 0.51562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08500\n",
      "Iter 64, Loss= 1.560449, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08500\n",
      "Iter 65, Loss= 1.572800, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09500\n",
      "Iter 66, Loss= 1.471747, Training Accuracy= 0.51562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.05750\n",
      "Iter 67, Loss= 1.306551, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07500\n",
      "Iter 68, Loss= 1.410614, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 69, Loss= 1.522233, Training Accuracy= 0.48438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08500\n",
      "Iter 70, Loss= 1.517756, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.11250\n",
      "Iter 71, Loss= 1.535687, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09500\n",
      "Iter 72, Loss= 1.476694, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09500\n",
      "Iter 73, Loss= 1.334623, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07500\n",
      "Iter 74, Loss= 1.545150, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10000\n",
      "Iter 75, Loss= 1.523667, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09500\n",
      "Iter 76, Loss= 1.398035, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.07500\n",
      "Iter 77, Loss= 1.445562, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09250\n",
      "Iter 78, Loss= 1.274136, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10000\n",
      "Iter 79, Loss= 1.429279, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.08750\n",
      "Iter 80, Loss= 1.473425, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09000\n",
      "Iter 81, Loss= 1.435339, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.09000\n",
      "Iter 82, Loss= 1.522432, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10500\n",
      "Iter 83, Loss= 1.362282, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10500\n",
      "Iter 84, Loss= 1.306241, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.10750\n",
      "Iter 85, Loss= 1.417763, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.09500\n",
      "Iter 86, Loss= 1.343283, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.11500\n",
      "Iter 87, Loss= 1.351031, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.11500\n",
      "Iter 88, Loss= 0.980640, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.12000\n",
      "Iter 89, Loss= 1.248711, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.12250\n",
      "Iter 90, Loss= 1.319393, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.12750\n",
      "Iter 91, Loss= 1.203843, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.13000\n",
      "Iter 92, Loss= 1.014292, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.13250\n",
      "Iter 93, Loss= 1.184726, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.13500\n",
      "Iter 94, Loss= 1.191552, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.13250\n",
      "Iter 95, Loss= 1.329172, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.15250\n",
      "Iter 96, Loss= 1.263589, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.15500\n",
      "Iter 97, Loss= 1.411410, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.16750\n",
      "Iter 98, Loss= 1.300603, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.15250\n",
      "Iter 99, Loss= 1.313490, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.15500\n",
      "Iter 100, Loss= 1.240057, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.16500\n",
      "Iter 101, Loss= 1.298534, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.17750\n",
      "Iter 102, Loss= 1.391566, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.19250\n",
      "Iter 103, Loss= 1.361940, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.20250\n",
      "Iter 104, Loss= 1.181175, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.20500\n",
      "Iter 105, Loss= 1.133613, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.21750\n",
      "Iter 106, Loss= 1.351392, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.22500\n",
      "Iter 107, Loss= 1.214966, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.23000\n",
      "Iter 108, Loss= 1.361650, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.23750\n",
      "Iter 109, Loss= 1.174031, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.25000\n",
      "Iter 110, Loss= 1.223785, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.25500\n",
      "Iter 111, Loss= 1.154907, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.26500\n",
      "Iter 112, Loss= 1.262268, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.26500\n",
      "Iter 113, Loss= 1.272573, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.27750\n",
      "Iter 114, Loss= 1.208752, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.29000\n",
      "Iter 115, Loss= 1.244526, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.29250\n",
      "Iter 116, Loss= 1.223801, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.29750\n",
      "Iter 117, Loss= 1.297656, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.30500\n",
      "Iter 118, Loss= 1.582061, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31000\n",
      "Iter 119, Loss= 1.278333, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31250\n",
      "Iter 120, Loss= 1.402692, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31500\n",
      "Iter 121, Loss= 1.251515, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31500\n",
      "Iter 122, Loss= 1.436526, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31500\n",
      "Iter 123, Loss= 1.393692, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.31750\n",
      "Iter 124, Loss= 1.368161, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.32000\n",
      "Iter 125, Loss= 1.224937, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.33000\n",
      "Iter 126, Loss= 1.264033, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.33000\n",
      "Iter 127, Loss= 1.290606, Training Accuracy= 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.33500\n",
      "Iter 128, Loss= 1.327211, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.34250\n",
      "Iter 129, Loss= 0.989025, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.35250\n",
      "Iter 130, Loss= 1.270636, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.35000\n",
      "Iter 131, Loss= 1.204049, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.35500\n",
      "Iter 132, Loss= 1.236669, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.36000\n",
      "Iter 133, Loss= 1.312899, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.36000\n",
      "Iter 134, Loss= 1.238329, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.36750\n",
      "Iter 135, Loss= 1.051767, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.37250\n",
      "Iter 136, Loss= 1.375082, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.37500\n",
      "Iter 137, Loss= 1.183232, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.37750\n",
      "Iter 138, Loss= 1.211952, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.38000\n",
      "Iter 139, Loss= 1.402569, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.38750\n",
      "Iter 140, Loss= 1.184294, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.38750\n",
      "Iter 141, Loss= 1.399361, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.39250\n",
      "Iter 142, Loss= 1.194048, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.39750\n",
      "Iter 143, Loss= 1.317772, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.40250\n",
      "Iter 144, Loss= 1.384110, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.40500\n",
      "Iter 145, Loss= 1.101900, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.40750\n",
      "Iter 146, Loss= 1.079211, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.41000\n",
      "Iter 147, Loss= 1.270495, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42000\n",
      "Iter 148, Loss= 1.257999, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42250\n",
      "Iter 149, Loss= 1.196230, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42500\n",
      "Iter 150, Loss= 1.157365, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42500\n",
      "Iter 151, Loss= 1.171185, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 152, Loss= 1.141360, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43250\n",
      "Iter 153, Loss= 1.398012, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43250\n",
      "Iter 154, Loss= 1.122055, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43500\n",
      "Iter 155, Loss= 1.314211, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43500\n",
      "Iter 156, Loss= 1.534713, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43500\n",
      "Iter 157, Loss= 1.498686, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43250\n",
      "Iter 158, Loss= 1.297737, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43250\n",
      "Iter 159, Loss= 1.158230, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43000\n",
      "Iter 160, Loss= 1.366146, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43250\n",
      "Iter 161, Loss= 1.272897, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 162, Loss= 1.146323, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.43000\n",
      "Iter 163, Loss= 1.220673, Training Accuracy= 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43000\n",
      "Iter 164, Loss= 1.492281, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 165, Loss= 1.351934, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 166, Loss= 1.167603, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 167, Loss= 1.163101, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.42750\n",
      "Iter 168, Loss= 1.216081, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.43500\n",
      "Iter 169, Loss= 1.255648, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44000\n",
      "Iter 170, Loss= 1.360895, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44000\n",
      "Iter 171, Loss= 1.021326, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44250\n",
      "Iter 172, Loss= 1.305650, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45250\n",
      "Iter 173, Loss= 1.231434, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45250\n",
      "Iter 174, Loss= 1.388473, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45000\n",
      "Iter 175, Loss= 1.148932, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45000\n",
      "Iter 176, Loss= 1.461969, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44750\n",
      "Iter 177, Loss= 1.168710, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44750\n",
      "Iter 178, Loss= 1.469560, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44750\n",
      "Iter 179, Loss= 1.263856, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44500\n",
      "Iter 180, Loss= 1.295301, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.44500\n",
      "Iter 181, Loss= 1.306356, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45000\n",
      "Iter 182, Loss= 1.423654, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45250\n",
      "Iter 183, Loss= 1.206730, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.45500\n",
      "Iter 184, Loss= 1.348100, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.46000\n",
      "Iter 185, Loss= 1.234579, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 186, Loss= 1.157605, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 187, Loss= 1.001738, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 188, Loss= 1.533788, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 189, Loss= 1.461286, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 190, Loss= 1.321313, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 191, Loss= 1.391395, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47500\n",
      "Iter 192, Loss= 1.242381, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47500\n",
      "Iter 193, Loss= 1.221442, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47500\n",
      "Iter 194, Loss= 1.099552, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47500\n",
      "Iter 195, Loss= 1.149129, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 196, Loss= 1.353405, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 197, Loss= 1.250076, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47500\n",
      "Iter 198, Loss= 1.164037, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 199, Loss= 1.024238, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.47250\n",
      "Iter 200, Loss= 1.150516, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.48250\n",
      "Iter 201, Loss= 1.313336, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.48000\n",
      "Iter 202, Loss= 1.198682, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.48000\n",
      "Iter 203, Loss= 1.069148, Training Accuracy= 0.73438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.48250\n",
      "Iter 204, Loss= 1.232494, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.48500\n",
      "Iter 205, Loss= 1.121377, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49000\n",
      "Iter 206, Loss= 1.176873, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49000\n",
      "Iter 207, Loss= 1.259660, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49000\n",
      "Iter 208, Loss= 1.224778, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49000\n",
      "Iter 209, Loss= 1.175776, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49500\n",
      "Iter 210, Loss= 0.936215, Training Accuracy= 0.73438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49500\n",
      "Iter 211, Loss= 1.232698, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49500\n",
      "Iter 212, Loss= 1.150546, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.49500\n",
      "Iter 213, Loss= 1.191387, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.50000\n",
      "Iter 214, Loss= 1.151750, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.50750\n",
      "Iter 215, Loss= 1.270119, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 216, Loss= 1.367955, Training Accuracy= 0.50000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 217, Loss= 1.501548, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 218, Loss= 1.489083, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 219, Loss= 1.244419, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 220, Loss= 1.400780, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51250\n",
      "Iter 221, Loss= 1.301383, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51500\n",
      "Iter 222, Loss= 1.317523, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51500\n",
      "Iter 223, Loss= 1.252794, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51750\n",
      "Iter 224, Loss= 1.371532, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.51750\n",
      "Iter 225, Loss= 1.225955, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.52250\n",
      "Iter 226, Loss= 1.292405, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.52250\n",
      "Iter 227, Loss= 1.265491, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.52250\n",
      "Iter 228, Loss= 1.431231, Training Accuracy= 0.53125\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53000\n",
      "Iter 229, Loss= 1.316995, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53250\n",
      "Iter 230, Loss= 1.397499, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 231, Loss= 1.152030, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 232, Loss= 1.448969, Training Accuracy= 0.54688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 233, Loss= 1.062374, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 234, Loss= 1.324026, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 235, Loss= 1.081483, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 236, Loss= 1.241676, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 237, Loss= 1.178270, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 238, Loss= 1.204070, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 239, Loss= 1.137135, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 240, Loss= 1.284637, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 241, Loss= 1.268846, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 242, Loss= 1.209188, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 243, Loss= 1.119289, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.54000\n",
      "Iter 244, Loss= 1.286838, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 245, Loss= 1.007021, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 246, Loss= 1.165454, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 247, Loss= 1.197924, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 248, Loss= 1.183702, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 249, Loss= 1.239195, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 250, Loss= 1.050368, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 251, Loss= 1.139124, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 252, Loss= 1.275778, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 253, Loss= 1.276799, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 254, Loss= 1.378233, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 255, Loss= 1.206948, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 256, Loss= 1.161559, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 257, Loss= 1.180507, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 258, Loss= 1.293120, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 259, Loss= 1.222043, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 260, Loss= 1.179401, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 261, Loss= 1.136539, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 262, Loss= 1.451222, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 263, Loss= 1.523578, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 264, Loss= 1.065122, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 265, Loss= 1.251383, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 266, Loss= 1.387548, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 267, Loss= 1.173364, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 268, Loss= 1.354342, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 269, Loss= 0.932488, Training Accuracy= 0.75000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 270, Loss= 1.179024, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 271, Loss= 1.199663, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 272, Loss= 1.171909, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 273, Loss= 1.218896, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 274, Loss= 1.138547, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 275, Loss= 1.393756, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 276, Loss= 1.426702, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 277, Loss= 1.325244, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 278, Loss= 1.234180, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 279, Loss= 1.260678, Training Accuracy= 0.73438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 280, Loss= 1.407260, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 281, Loss= 1.240587, Training Accuracy= 0.60938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 282, Loss= 1.230727, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 283, Loss= 1.267970, Training Accuracy= 0.70312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 284, Loss= 1.639167, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 285, Loss= 1.176879, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 286, Loss= 1.376287, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 287, Loss= 1.131633, Training Accuracy= 0.67188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 288, Loss= 1.216641, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 289, Loss= 1.215152, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 290, Loss= 1.280414, Training Accuracy= 0.62500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 291, Loss= 1.161209, Training Accuracy= 0.56250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54250\n",
      "Iter 292, Loss= 1.249611, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 293, Loss= 1.328319, Training Accuracy= 0.57812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 294, Loss= 1.288503, Training Accuracy= 0.59375\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53500\n",
      "Iter 295, Loss= 1.281949, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n",
      "Iter 296, Loss= 1.133924, Training Accuracy= 0.71875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 297, Loss= 1.209346, Training Accuracy= 0.64062\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 298, Loss= 1.142808, Training Accuracy= 0.65625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.54000\n",
      "Iter 299, Loss= 1.330186, Training Accuracy= 0.68750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.53750\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for i in range(training_epoch):\n",
    "            train_X=random_crop(normalize(padding(train_sounds))) # Choosing randomly a 1.5s section\n",
    "            train_X = np.reshape(train_X, (-1, 24014, 1, 1)) # Reshape to have 1D input\n",
    "            for batch in range(len(train_X)//batch_size):\n",
    "                batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "                batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "                    # Run optimization op (backprop).\n",
    "                        # Calculate batch loss and accuracy\n",
    "                opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n",
    "                                                         keep_prob:0.5, is_training:True, \n",
    "                                                         learning_rate:lr(i)})\n",
    "                loss, acc = sess.run([cost, accuracy_train], feed_dict={X: batch_x, y: batch_y, \n",
    "                                                                         keep_prob:0.5, is_training:True,\n",
    "                                                                     learning_rate:lr(i)})\n",
    "            print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                              \"{:.5f}\".format(acc))\n",
    "            print(\"Optimization Finished!\")\n",
    "            \n",
    "            acc_test=[]\n",
    "            for crop in range(len(test_X)//crop_size):\n",
    "                crop_x = test_X[crop*crop_size:min((crop+1)*crop_size,len(test_X))]\n",
    "                crop_y = test_y[crop*crop_size:min((crop+1)*crop_size,len(test_y))] \n",
    "                \n",
    "                acc_t= sess.run([accuracy_test], feed_dict={X: crop_x, y : crop_y, \n",
    "                                                                           keep_prob:1.0, is_training:False,\n",
    "                                                            learning_rate:lr(i)})\n",
    "                acc_test.append(acc_t)\n",
    "               \n",
    "            test_acc=np.mean(acc_test)\n",
    "            #print(len(acc_test))\n",
    "            \n",
    "            train_loss.append(loss)\n",
    "            #test_loss.append(valid_loss)\n",
    "            train_accuracy.append(acc)\n",
    "            test_accuracy.append(test_acc)\n",
    "            print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7febc6030240>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracy)\n",
    "plt.plot(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO/REMARKS : \n",
    "- Accuracy for now : 0.2950 (with my dataset), 0.35750 (with their dataset)\n",
    "- With only 3 classes (baby crying, glass breaking, coughing) : 0.6250 \n",
    "- why is training accuracy low ?\n",
    "- check for silent windows -> remove them\n",
    "- why 10 crops for testing phase ?\n",
    "- Accuracy with the new testing scheme + 150 training epochs : 0.365 (with my dataset), 0.48 (with their dataset)\n",
    "- 230 traning epochs, testing accuracy : 0.54\n",
    "- Test on another dataset\n",
    "- Semi-supervised learning ?\n",
    "- Check to remove silent windows in test set ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
