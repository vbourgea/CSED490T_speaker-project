{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFolds = 5\n",
    "n_classes = 50\n",
    "n_splits = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels):\n",
    "    b = np.zeros((len(labels), n_classes))\n",
    "    b[np.arange(len(labels)), labels] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(split):\n",
    "    dataset = np.load(os.path.join('.','wav16.npz'))\n",
    "    # Split to train and val\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    val_sounds = []\n",
    "    val_labels = []\n",
    "    for i in range(1, nFolds + 1):\n",
    "        sounds = dataset['fold{}'.format(i)].item()['sounds']\n",
    "        labels = dataset['fold{}'.format(i)].item()['labels']\n",
    "        if i == split:\n",
    "            val_sounds.extend(sounds)\n",
    "            val_labels.extend(labels)\n",
    "        else:\n",
    "            train_sounds.extend(sounds)\n",
    "            train_labels.extend(labels)\n",
    "                  \n",
    "    train_labels= one_hot_encoding(train_labels)\n",
    "    val_labels= one_hot_encoding(val_labels)\n",
    "    \n",
    "    return train_sounds,train_labels, val_sounds,val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name={'crying_baby':0, 'glass_breaking':1, 'coughing':2}\n",
    "#train_labels=list(map(name.get, train_labels))\n",
    "#val_labels=list(map(name.get, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to have value between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound, factor=32768):\n",
    "    return [s/factor for s in sound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random crop of the sound values to have T-s window of sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(sound, size=24014):\n",
    "    cropped_sound=[]\n",
    "    for s in sound:\n",
    "        org_size = len(s)\n",
    "        start = random.randint(0, org_size - size)\n",
    "        cropped_s=s[start: start + size]\n",
    "        cropped_sound.append(cropped_s)\n",
    "    return cropped_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sound, pad=24014//2):\n",
    "    padded_sound=[]\n",
    "    for i in range(len(sound)):\n",
    "        padded_s=np.pad(sound[i], pad, 'constant')\n",
    "        padded_sound.append(padded_s)\n",
    "    return padded_sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-crop for testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_crop(sounds,input_length=24014, n_crops=10):\n",
    "    multi_cropped_sounds=[]\n",
    "    for s in sounds:\n",
    "        stride = (len(s) - input_length) // (n_crops - 1)\n",
    "        multi_cropped_sound = [s[stride * i: stride * i + input_length] for i in range(n_crops)]\n",
    "        multi_cropped_sounds.append(np.array(multi_cropped_sound))\n",
    "    return multi_cropped_sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scale(sounds,max_scale=1.25, interpolate='Linear'):\n",
    "    sounds_augmented=[]\n",
    "    for s in sounds:\n",
    "        scale = np.power(max_scale, random.uniform(-1, 1))\n",
    "        output_size = int(len(s) * scale)\n",
    "        ref = np.arange(output_size) / scale\n",
    "        if interpolate == 'Linear':\n",
    "            ref1 = ref.astype(np.int32)\n",
    "            ref2 = np.minimum(ref1 + 1, len(s) - 1)\n",
    "            r = ref - ref1\n",
    "            scaled_sound = s[ref1] * (1 - r) + s[ref2] * r\n",
    "        elif interpolate == 'Nearest':\n",
    "            scaled_sound = s[ref.astype(np.int32)]\n",
    "        else:\n",
    "            raise Exception('Invalid interpolation mode {}'.format(interpolate))\n",
    "\n",
    "        sounds_augmented.append(scaled_sound)\n",
    "    return sounds_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is supposed to be the pad parameter ?\n",
    "#train_sounds=padding(train_sounds, 24014//2) \n",
    "#val_sounds=padding(train_sounds, 24014//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of window = 1.5s (24014)\n",
    "\n",
    "Normalization constant = 32768 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the tensor is 4D : [batch, height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 24014,1, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 150 \n",
    "batch_size = 64\n",
    "learning_rate = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lr decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(epoch):\n",
    "    if (0<=epoch<=80):\n",
    "        return 0.01\n",
    "    if (80<epoch<=100):\n",
    "        return 0.001\n",
    "    if (100<epoch<= 120):\n",
    "        return 0.0001\n",
    "    else: return 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride =1\n",
    "\n",
    "No Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b,is_training, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.contrib.layers.batch_norm(x, is_training=is_training)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k_h=2, k_w=2): #non-overlapping max-pooling\n",
    "    return tf.nn.max_pool(x, ksize=[1, k_h, k_w, 1], strides=[1, k_h, k_w, 1],padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of the parameters = He initialization\n",
    "\n",
    "Review the order (does the order actually matters ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[heigth_filter, width_filter, depth_filter, number of filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    #conv1\n",
    "    'wc1': tf.get_variable('W0', shape=(8,1,1,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv2\n",
    "    'wc2': tf.get_variable('W1', shape=(8,1,40,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv3\n",
    "    'wc3': tf.get_variable('W2', shape=(13,8,1,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv4\n",
    "    'wc4': tf.get_variable('W3', shape=(5,1,50,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc5': tf.get_variable('W4', shape=(50*11*14,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc6': tf.get_variable('W5', shape=(4096,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #output\n",
    "    'out': tf.get_variable('W6', shape=(4096,n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc2': tf.get_variable('B1', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc3': tf.get_variable('B2', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc4': tf.get_variable('B3', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc5': tf.get_variable('B4', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc6': tf.get_variable('B5', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'out': tf.get_variable('B6', shape=(n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_net(x, weights, biases):  \n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], is_training)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], is_training)\n",
    "    conv2 = maxpool2d(conv2, k_h=160, k_w=1)\n",
    "    \n",
    "    conv2=tf.reshape(conv2, [-1, 150, 40, 1])\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], is_training)\n",
    "    conv3 = maxpool2d(conv3, k_h=3, k_w=3)\n",
    "    \n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'], is_training)\n",
    "    conv4 = maxpool2d(conv4, k_h=3, k_w=1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc5 = tf.reshape(conv4, [-1, weights['wfc5'].get_shape().as_list()[0]])\n",
    "    fc5 = tf.add(tf.matmul(fc5, weights['wfc5']), biases['bfc5'])\n",
    "    fc5 = tf.nn.relu(fc5)\n",
    "    # Drop out\n",
    "    drop_out_fc5 = tf.nn.dropout(fc5, keep_prob)\n",
    "    \n",
    "    fc6 = tf.add(tf.matmul(drop_out_fc5, weights['wfc6']), biases['bfc6'])\n",
    "    fc6 = tf.nn.relu(fc6)\n",
    "    drop_out_fc6 = tf.nn.dropout(fc6, keep_prob)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(drop_out_fc6, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & optimizer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_momentum = 0.9\n",
    "momentum = tf.Variable(init_momentum, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta=5e-4 \n",
    "\n",
    "pred = env_net(X, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "\n",
    "# regularizers = tf.nn.l2_loss(weights['wc1']) + tf.nn.l2_loss(weights['wc2']) + \\\n",
    "#                 tf.nn.l2_loss(weights['wc3']) + tf.nn.l2_loss(weights['wc4']) + \\\n",
    "#                 tf.nn.l2_loss(weights['wfc5']) + tf.nn.l2_loss(weights['wfc6']) + \\\n",
    "#                 tf.nn.l2_loss(weights['out'])\n",
    "\n",
    "# cost = tf.reduce_mean(cost + beta * regularizers)\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "#correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "correct_prediction_train = tf.equal(tf.argmax(pred_train, 1), tf.argmax(y, 1))\n",
    "correct_prediction_test = tf.equal(tf.argmax(pred_test, 0), tf.argmax(y, 1)[0])\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy_train = tf.reduce_mean(tf.cast(correct_prediction_train, tf.float32))\n",
    "accuracy_test=tf.cast(correct_prediction_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate the version of Perla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(split,train_loss,train_accuracy,test_loss,test_accuracy):\n",
    "    train_sounds,train_y, val_sounds,test_y=setup(split)\n",
    "    for i in range(training_epoch):\n",
    "        train_X=random_crop(normalize(padding(random_scale(train_sounds))))  # Choosing randomly a 1.5s section\n",
    "        train_X = np.reshape(train_X, (-1, 24014, 1, 1)) # Reshape to have 1D input\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "                # Run optimization op (backprop).\n",
    "                    # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n",
    "                                                     keep_prob:0.5, is_training:True, \n",
    "                                                     learning_rate:lr(i)})\n",
    "            loss, acc = sess.run([cost, accuracy_train], feed_dict={X: batch_x, y: batch_y, \n",
    "                                                                     keep_prob:0.5, is_training:True,\n",
    "                                                                 learning_rate:lr(i)})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                          \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        acc_test=[]\n",
    "        for crop in range(len(test_X)//crop_size):\n",
    "            crop_x = test_X[crop*crop_size:min((crop+1)*crop_size,len(test_X))]\n",
    "            crop_y = test_y[crop*crop_size:min((crop+1)*crop_size,len(test_y))] \n",
    "\n",
    "            acc_t= sess.run([accuracy_test], feed_dict={X: crop_x, y : crop_y, \n",
    "                                                                       keep_prob:1.0, is_training:False,\n",
    "                                                        learning_rate:lr(i)})\n",
    "            acc_test.append(acc_t)\n",
    "\n",
    "        test_acc=np.mean(acc_test)\n",
    "        #print(len(acc_test))\n",
    "\n",
    "        train_loss.append(loss)\n",
    "        #test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(split,train_loss,train_accuracy,test_accuracy):\n",
    "    train_sounds,train_y, val_sounds,test_y=setup(split)\n",
    "    for i in range(training_epoch):\n",
    "        train_X=random_crop(normalize(padding(train_sounds))) # Choosing randomly a 1.5s section\n",
    "        train_X = np.reshape(train_X, (-1, 24014, 1, 1)) # Reshape to have 1D input\n",
    "        test_X=random_crop(normalize(padding(val_sounds)))\n",
    "        test_X = np.reshape(test_X, (-1, 24014, 1, 1))\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "                # Run optimization op (backprop).\n",
    "                    # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n",
    "                                                     keep_prob:0.5, is_training:True, \n",
    "                                                     learning_rate:lr(i)})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x, y: batch_y, \n",
    "                                                                     keep_prob:0.5, is_training:True,\n",
    "                                                                 learning_rate:lr(i)})\n",
    "        train_loss.append(loss)\n",
    "        train_accuracy.append(acc)\n",
    " \n",
    "        test_acc = sess.run([accuracy], feed_dict={X: test_X, y : test_y, \n",
    "                                                                        keep_prob:1.0, is_training:False,\n",
    "                                                                        learning_rate:lr(i)})\n",
    "        test_accuracy.append(test_acc[0])\n",
    "        if i % 10 == 0:\n",
    "            print('| Epoch: {}/{} | Train: LR {}  Loss {:.6f} Training Accuracy : {:.3f} Testing Accuracy: {:.2f}\\n'.format(\n",
    "                        i, training_epoch, lr(i), train_loss[i],train_accuracy[i],test_accuracy[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(split,train_loss,train_accuracy,test_loss,test_accuracy):\n",
    "    train_sounds,train_y, val_sounds,test_y=setup(split)\n",
    "    for i in range(training_epoch):\n",
    "        train_X=random_crop(normalize(padding(random_scale(train_sounds)))) # Choosing randomly a 1.5s section\n",
    "        train_X = np.reshape(train_X, (-1, 24014, 1, 1)) # Reshape to have 1D input\n",
    "        test_X=random_crop(normalize(padding(val_sounds)))\n",
    "        test_X = np.reshape(test_X, (-1, 24014, 1, 1))\n",
    "        loss_by_epoch=0\n",
    "        acc_by_epoch=0\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "            # Run optimization op (backprop).\n",
    "            # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n",
    "                                                     keep_prob:0.5, is_training:True, \n",
    "                                                     learning_rate:lr(i)})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x, y: batch_y, \n",
    "                                                                     keep_prob:0.5, is_training:True,\n",
    "                                                                 learning_rate:lr(i)})\n",
    "            loss_by_epoch+=loss*len(batch_y)\n",
    "            acc_by_epoch+=acc*len(batch_y)\n",
    "        loss_by_epoch/= len(train_y)\n",
    "        train_loss.append(loss_by_epoch)\n",
    "        \n",
    "        acc_by_epoch = 100 * (acc_by_epoch / len(train_y))\n",
    "        train_accuracy.append(acc_by_epoch)\n",
    "        \n",
    "        loss_acc,test_acc = sess.run([cost,accuracy], feed_dict={X: test_X, y : test_y, \n",
    "                                                                        keep_prob:1.0, is_training:False,\n",
    "                                                                        learning_rate:lr(i)})\n",
    "        test_accuracy.append(test_acc*100)\n",
    "        test_loss.append(loss_acc*100)\n",
    "        if i % 10 == 0 or i == training_epoch-1:\n",
    "            print('| Epoch: {}/{} | Train: LR {}  Loss {:.6f} Training Accuracy : {:.3f} Testing Accuracy: {:.2f}\\n'.format(\n",
    "                        i+1, training_epoch, lr(i), train_loss[i],train_accuracy[i],test_accuracy[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- Split 1 --+\n",
      "| Epoch: 1/150 | Train: LR 0.01  Loss 5.074906 Training Accuracy : 6.562 Testing Accuracy: 2.00\n",
      "\n",
      "| Epoch: 11/150 | Train: LR 0.01  Loss 3.202474 Training Accuracy : 14.375 Testing Accuracy: 4.25\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-2df4bd531aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+-- Split {} --+'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-20606aa18f1d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(split, train_loss, train_accuracy, test_loss, test_accuracy)\u001b[0m\n\u001b[1;32m     15\u001b[0m             opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n\u001b[1;32m     16\u001b[0m                                                      \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                                      learning_rate:lr(i)})\n\u001b[0m\u001b[1;32m     18\u001b[0m             loss, acc = sess.run([cost, accuracy], feed_dict={X: batch_x, y: batch_y, \n\u001b[1;32m     19\u001b[0m                                                                      \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dl5/venv10/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:1\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = [ [] for i in range(n_splits) ]\n",
    "        train_accuracy = [ [] for i in range(n_splits) ]\n",
    "        test_loss = [ [] for i in range(n_splits) ]\n",
    "        test_accuracy = [ [] for i in range(n_splits) ]\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for split in range(1,n_splits+1):\n",
    "            print('+-- Split {} --+'.format(split))\n",
    "            train(split,train_loss[split-1],train_accuracy[split-1],test_loss[split-1],test_accuracy[split-1])            \n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- Split 1 --+\n",
      "| Epoch: 0/150 | Train: LR 0.01  Loss 5.147108 Training Accuracy : 7.187 Testing Accuracy: 0.02\n",
      "\n",
      "| Epoch: 10/150 | Train: LR 0.01  Loss 3.204636 Training Accuracy : 13.875 Testing Accuracy: 0.07\n",
      "\n",
      "| Epoch: 20/150 | Train: LR 0.01  Loss 2.652540 Training Accuracy : 25.625 Testing Accuracy: 0.04\n",
      "\n",
      "| Epoch: 30/150 | Train: LR 0.01  Loss 2.282438 Training Accuracy : 34.500 Testing Accuracy: 0.04\n",
      "\n",
      "| Epoch: 40/150 | Train: LR 0.01  Loss 2.013028 Training Accuracy : 40.312 Testing Accuracy: 0.03\n",
      "\n",
      "| Epoch: 50/150 | Train: LR 0.01  Loss 1.729627 Training Accuracy : 49.562 Testing Accuracy: 0.05\n",
      "\n",
      "| Epoch: 60/150 | Train: LR 0.01  Loss 1.564614 Training Accuracy : 53.938 Testing Accuracy: 0.06\n",
      "\n",
      "| Epoch: 70/150 | Train: LR 0.01  Loss 1.370370 Training Accuracy : 59.188 Testing Accuracy: 0.06\n",
      "\n",
      "| Epoch: 80/150 | Train: LR 0.01  Loss 1.270736 Training Accuracy : 62.313 Testing Accuracy: 0.09\n",
      "\n",
      "| Epoch: 90/150 | Train: LR 0.001  Loss 1.172295 Training Accuracy : 65.625 Testing Accuracy: 0.09\n",
      "\n",
      "| Epoch: 100/150 | Train: LR 0.001  Loss 1.104912 Training Accuracy : 65.938 Testing Accuracy: 0.12\n",
      "\n",
      "| Epoch: 110/150 | Train: LR 0.0001  Loss 1.091891 Training Accuracy : 66.875 Testing Accuracy: 0.16\n",
      "\n",
      "| Epoch: 120/150 | Train: LR 0.0001  Loss 1.167822 Training Accuracy : 65.375 Testing Accuracy: 0.23\n",
      "\n",
      "| Epoch: 130/150 | Train: LR 1e-05  Loss 1.113652 Training Accuracy : 67.000 Testing Accuracy: 0.27\n",
      "\n",
      "| Epoch: 140/150 | Train: LR 1e-05  Loss 1.105337 Training Accuracy : 66.812 Testing Accuracy: 0.31\n",
      "\n",
      "| Epoch: 149/150 | Train: LR 1e-05  Loss 1.061071 Training Accuracy : 68.375 Testing Accuracy: 0.36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:1\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = [ [] for i in range(n_splits) ]\n",
    "        train_accuracy = [ [] for i in range(n_splits) ]\n",
    "        test_loss = [ [] for i in range(n_splits) ]\n",
    "        test_accuracy = [ [] for i in range(n_splits) ]\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for split in range(1,n_splits+1):\n",
    "            print('+-- Split {} --+'.format(split))\n",
    "            train(split,train_loss[split-1],train_accuracy[split-1],test_loss[split-1],test_accuracy[split-1])            \n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- Split 1 --+\n",
      "| Epoch: 0/150 | Train: LR 0.01  Loss 5.077315 Testing Accuracy: 0.02\n",
      "\n",
      "| Epoch: 10/150 | Train: LR 0.01  Loss 3.152364 Testing Accuracy: 0.05\n",
      "\n",
      "| Epoch: 20/150 | Train: LR 0.01  Loss 2.567582 Testing Accuracy: 0.05\n",
      "\n",
      "| Epoch: 30/150 | Train: LR 0.01  Loss 2.201598 Testing Accuracy: 0.03\n",
      "\n",
      "| Epoch: 40/150 | Train: LR 0.01  Loss 1.889521 Testing Accuracy: 0.04\n",
      "\n",
      "| Epoch: 50/150 | Train: LR 0.01  Loss 1.672241 Testing Accuracy: 0.04\n",
      "\n",
      "| Epoch: 60/150 | Train: LR 0.01  Loss 1.490539 Testing Accuracy: 0.05\n",
      "\n",
      "| Epoch: 70/150 | Train: LR 0.01  Loss 1.278729 Testing Accuracy: 0.07\n",
      "\n",
      "| Epoch: 80/150 | Train: LR 0.01  Loss 1.243228 Testing Accuracy: 0.08\n",
      "\n",
      "| Epoch: 90/150 | Train: LR 0.001  Loss 1.110288 Testing Accuracy: 0.10\n",
      "\n",
      "| Epoch: 100/150 | Train: LR 0.001  Loss 1.034573 Testing Accuracy: 0.13\n",
      "\n",
      "| Epoch: 110/150 | Train: LR 0.0001  Loss 1.052393 Testing Accuracy: 0.20\n",
      "\n",
      "| Epoch: 120/150 | Train: LR 0.0001  Loss 1.011366 Testing Accuracy: 0.25\n",
      "\n",
      "| Epoch: 130/150 | Train: LR 1e-05  Loss 0.984093 Testing Accuracy: 0.29\n",
      "\n",
      "| Epoch: 140/150 | Train: LR 1e-05  Loss 1.013516 Testing Accuracy: 0.30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:1\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = [ [] for i in range(n_splits) ]\n",
    "        train_accuracy = [ [] for i in range(n_splits) ]\n",
    "        test_accuracy = [ [] for i in range(n_splits) ]\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for split in range(1,n_splits+1):\n",
    "            print('+-- Split {} --+'.format(split))\n",
    "            train(split,train_loss[split-1],train_accuracy[split-1],test_accuracy[split-1])            \n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:1\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = [ [] for i in range(nFolds) ]\n",
    "        train_accuracy = [ [] for i in range(nFolds) ]\n",
    "        test_accuracy = [ [] for i in range(nFolds) ]\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for split in range(1,nFolds+1):\n",
    "            print('+-- Split {} --+'.format(split))\n",
    "            train(split,train_loss[split-1],train_accuracy[split-1],test_accuracy[split-1])            \n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO : \n",
    "- looks like it's overfitting (check if drop out is working)\n",
    "- look if there is a bug somewhere\n",
    "- look padding function ? what is the use ?\n",
    "- maybe a problem with the testing phase ? what is multi_crop function ?\n",
    "- Accuracy for now : 0.2950 (with my dataset), 0.35750 (with their dataset)\n",
    "- why is training accuracy low ?\n",
    "- check for silent windows -> remove them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
