{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perla's code for only 26 classes -wonbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.load('wav16.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into train & validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=3\n",
    "# Split to train and val\n",
    "train_sounds = []\n",
    "train_labels = []\n",
    "val_sounds = []\n",
    "val_labels = []\n",
    "for i in range(1, 6):\n",
    "    sounds = dataset['fold{}'.format(i)].item()['sounds']\n",
    "    labels = dataset['fold{}'.format(i)].item()['labels']\n",
    "    if i == split:\n",
    "        val_sounds.extend(sounds)\n",
    "        val_labels.extend(labels)\n",
    "    else:\n",
    "        train_sounds.extend(sounds)\n",
    "        train_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I just added this one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_labels = [0, 5, 10, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28 ,29, 30, 32, 33, 35, 36, 37, 39, 42, 43]\n",
    "a_labels = []\n",
    "a_sounds = []\n",
    "b_labels = []\n",
    "b_sounds = []\n",
    "for i in range(0, 1600):\n",
    "    if(train_labels[i] in chosen_labels):\n",
    "        new_label = chosen_labels.index(train_labels[i])\n",
    "        a_labels.insert(-1, new_label)\n",
    "        a_sounds.insert(-1, train_sounds[i])\n",
    "\n",
    "for i in range(0, 400):\n",
    "    if(val_labels[i] in chosen_labels):\n",
    "        new_label = chosen_labels.index(val_labels[i])\n",
    "        b_labels.insert(-1, new_label)\n",
    "        b_sounds.insert(-1, val_sounds[i])\n",
    "        \n",
    "train_labels = a_labels\n",
    "train_sounds = a_sounds\n",
    "val_labels = b_labels\n",
    "val_sounds = b_sounds\n",
    "\n",
    "print(len(train_labels))\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=one_hot_encode(train_labels)\n",
    "val_labels=one_hot_encode(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to have value between -1 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sound, factor=32768):\n",
    "    return [s/factor for s in sound]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random crop of the sound values to have T-s window of sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(sound, size=24014):\n",
    "    cropped_sound=[]\n",
    "    for s in sound:\n",
    "        org_size = len(s)\n",
    "        start = random.randint(0, org_size - size)\n",
    "        cropped_s=s[start: start + size]\n",
    "        cropped_sound.append(cropped_s)\n",
    "    return cropped_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(sound, pad=24014//2):\n",
    "    if len(sound)<80000:\n",
    "        padded_sound=[]\n",
    "        for i in range(len(sound)):\n",
    "            padded_s=np.pad(sound[i], pad, 'constant')\n",
    "            padded_sound.append(padded_s)\n",
    "    return padded_sound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-crop for testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_crop(sounds,input_length=24014, n_crops=10):\n",
    "    multi_cropped_sounds=[]\n",
    "    for s in sounds:\n",
    "        stride = (len(s) - input_length) // (n_crops - 1)\n",
    "        multi_cropped_sound = [s[stride * i: stride * i + input_length] for i in range(n_crops)]\n",
    "        multi_cropped_sounds.append(np.array(multi_cropped_sound))\n",
    "    return multi_cropped_sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is supposed to be the pad parameter ?\n",
    "#train_sounds=padding(train_sounds, 24014//2) \n",
    "#val_sounds=padding(train_sounds, 24014//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of window = 1.5s (24014)\n",
    "\n",
    "Normalization constant = 32768 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=train_labels\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X=multi_crop(normalize(padding(val_sounds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.reshape(test_X, (-1, 24014, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y=np.repeat(val_labels, 10, axis=0)\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_sounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve : do the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes=3\n",
    "n_classes=26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the tensor is 4D : [batch, height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 24014,1, 1])\n",
    "y = tf.placeholder(tf.float32, shape=[None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 300 \n",
    "batch_size = 64\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "crop_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr(epoch):\n",
    "    if (0<=epoch<=80):\n",
    "        return 0.01\n",
    "    if (80<epoch<=100):\n",
    "        return 0.001\n",
    "    if (100<epoch<= 120):\n",
    "        return 0.0001\n",
    "    else: return 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stride =1\n",
    "\n",
    "No Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b,is_training, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    x = tf.contrib.layers.batch_norm(x, is_training=is_training)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k_h=2, k_w=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k_h, k_w, 1], strides=[1, k_h, k_w, 1],padding='VALID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of the parameters = He initialization\n",
    "\n",
    "Review the order (does the order actually matters ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[heigth_filter, width_filter, depth_filter, number of filters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    #conv1\n",
    "    'wc1': tf.get_variable('W0', shape=(8,1,1,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv2\n",
    "    'wc2': tf.get_variable('W1', shape=(8,1,40,40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv3\n",
    "    'wc3': tf.get_variable('W2', shape=(13,8,1,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #conv4\n",
    "    'wc4': tf.get_variable('W3', shape=(5,1,50,50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc5': tf.get_variable('W4', shape=(50*11*14,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #fc5\n",
    "    'wfc6': tf.get_variable('W5', shape=(4096,4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    #output\n",
    "    'out': tf.get_variable('W6', shape=(4096,n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc2': tf.get_variable('B1', shape=(40), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc3': tf.get_variable('B2', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bc4': tf.get_variable('B3', shape=(50), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc5': tf.get_variable('B4', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'bfc6': tf.get_variable('B5', shape=(4096), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "    'out': tf.get_variable('B6', shape=(n_classes), initializer=tf.contrib.layers.variance_scaling_initializer(dtype=tf.float32)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_net(x, weights, biases):  \n",
    "\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'], is_training)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'], is_training)\n",
    "    conv2 = maxpool2d(conv2, k_h=160, k_w=1)\n",
    "    \n",
    "    conv2=tf.reshape(conv2, [-1, 150, 40, 1])\n",
    "    \n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'], is_training)\n",
    "    conv3 = maxpool2d(conv3, k_h=3, k_w=3)\n",
    "    \n",
    "    conv4 = conv2d(conv3, weights['wc4'], biases['bc4'], is_training)\n",
    "    conv4 = maxpool2d(conv4, k_h=3, k_w=1)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    fc5 = tf.reshape(conv4, [-1, weights['wfc5'].get_shape().as_list()[0]])\n",
    "    fc5 = tf.add(tf.matmul(fc5, weights['wfc5']), biases['bfc5'])\n",
    "    fc5 = tf.nn.relu(fc5)\n",
    "    # Drop out\n",
    "    drop_out_fc5 = tf.nn.dropout(fc5, keep_prob)\n",
    "    \n",
    "    fc6 = tf.add(tf.matmul(drop_out_fc5, weights['wfc6']), biases['bfc6'])\n",
    "    fc6 = tf.nn.relu(fc6)\n",
    "    drop_out_fc6 = tf.nn.dropout(fc6, keep_prob)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(drop_out_fc6, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss & optimizer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_momentum = 0.9\n",
    "momentum = tf.Variable(init_momentum, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = env_net(X, weights, biases)\n",
    "\n",
    "pred_train=logits\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred_train, labels=y))\n",
    "\n",
    "pred_test=tf.reduce_sum(tf.nn.softmax(logits),0)\n",
    "\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9, use_nesterov=True).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "#correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "correct_prediction_train = tf.equal(tf.argmax(pred_train, 1), tf.argmax(y, 1))\n",
    "correct_prediction_test = tf.equal(tf.argmax(pred_test, 0), tf.argmax(y, 1)[0])\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy_train = tf.reduce_mean(tf.cast(correct_prediction_train, tf.float32))\n",
    "accuracy_test=tf.cast(correct_prediction_test, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init) \n",
    "        train_loss = []\n",
    "        test_loss = []\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "        summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "        for i in range(training_epoch):\n",
    "            train_X=random_crop(normalize(padding(train_sounds))) # Choosing randomly a 1.5s section\n",
    "            train_X = np.reshape(train_X, (-1, 24014, 1, 1)) # Reshape to have 1D input\n",
    "            for batch in range(len(train_X)//batch_size):\n",
    "                batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "                batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "                    # Run optimization op (backprop).\n",
    "                        # Calculate batch loss and accuracy\n",
    "                opt = sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, \n",
    "                                                         keep_prob:0.5, is_training:True, \n",
    "                                                         learning_rate:lr(i)})\n",
    "                loss, acc = sess.run([cost, accuracy_train], feed_dict={X: batch_x, y: batch_y, \n",
    "                                                                         keep_prob:0.5, is_training:True,\n",
    "                                                                     learning_rate:lr(i)})\n",
    "            print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                              \"{:.5f}\".format(acc))\n",
    "            \n",
    "            acc_test=[]\n",
    "            for crop in range(len(test_X)//crop_size):\n",
    "                crop_x = test_X[crop*crop_size:min((crop+1)*crop_size,len(test_X))]\n",
    "                crop_y = test_y[crop*crop_size:min((crop+1)*crop_size,len(test_y))] \n",
    "                \n",
    "                acc_t= sess.run([accuracy_test], feed_dict={X: crop_x, y : crop_y, \n",
    "                                                                           keep_prob:1.0, is_training:False,\n",
    "                                                            learning_rate:lr(i)})\n",
    "                acc_test.append(acc_t)\n",
    "               \n",
    "            test_acc=np.mean(acc_test)\n",
    "            #print(len(acc_test))\n",
    "            \n",
    "            train_loss.append(loss)\n",
    "            #test_loss.append(valid_loss)\n",
    "            train_accuracy.append(acc)\n",
    "            test_accuracy.append(test_acc)\n",
    "            print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "        summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy)\n",
    "plt.plot(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO/REMARKS : \n",
    "- Accuracy for now : 0.2950 (with my dataset), 0.35750 (with their dataset)\n",
    "- With only 3 classes (baby crying, glass breaking, coughing) : 0.6250 \n",
    "- why is training accuracy low ?\n",
    "- check for silent windows -> remove them\n",
    "- why 10 crops for testing phase ?\n",
    "- Accuracy with the new testing scheme + 150 training epochs : 0.365 (with my dataset), 0.48 (with their dataset)\n",
    "- 230 traning epochs, testing accuracy : 0.54\n",
    "- Test on another dataset\n",
    "- Semi-supervised learning ?\n",
    "- Check to remove silent windows in test set ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
